#
# Be aware that even a small syntax error here can lead to failures in output.
#

sidebar:
    position: left # position of the sidebar : left or right
    about: False # set to False or comment line if you want to remove the "how to use?" in the sidebar
    education: True # set to False if you want education in main section instead of in sidebar

    # Profile information
    name: Mike Wilkins
    tagline: HPC/AI Researcher
    avatar: headshot.webp  #place a 100x100 picture inside /assets/images/ folder and provide the name of the file below

    # Sidebar links
    email: wilkins@u.northwestern.edu
    # timezone: America/Cancun Timezone
    # citizenship:
    # website: blog.webjeda.com #do not add http://
    linkedin: www.linkedin.com/in/michael-wilkins-46b7b6128
    # xing: alandoe
    # github: sharu725
    # telegram: # add your nickname without '@' sign
    # gitlab:
    # bitbucket:
    # twitter: '@webjeda'
    # stack-overflow: # Number/Username, e.g. 123456/alandoe
    # codewars:
    # goodreads: # Number-Username, e.g. 123456-alandoe
    # pdf: http://www.africau.edu/images/default/sample.pdf

    # languages:
    #  title: Languages
    #  info:
    #    - idiom: English
    #      level: Native
    #
    #    - idiom: French
    #      level: Professional
    #
    #    - idiom: Spanish
    #      level: Professional

    # interests:
    #  title: Interests
    #  info:
    #    - item: Climbing
    #      link:
    #
    #    - item: Snowboarding
    #      link:
    #
    #    - item: Cooking
    #      link:

career-profile:
    title: Welcome!
    summary: |
        My name is Mike Wilkins, and I research high-performance computing systems, specifically optimizing for scientific and AI workloads.
        I am currently a Maria Goeppert Mayer Fellow at Argonne National Laboratory, supervised by Dr. Yanfei Guo and
        Rajeev Thakur.
        I completed my Ph.D. in Computer Engineering at Northwestern University under the advisement of Dr. Peter Dinda and Dr. Nikos Hardavellas. 
        Below you will find details regarding my experiences and current/past projects.

education:
    title: Education
    info:
      - degree: Ph.D. Computer Engineering
        university: Northwestern University
        time: 2023
      - degree: M.S. Computer Engineering
        university: Northwestern University
        time: 2021
      - degree: B.S. Computer Engineering
        university: Rose-Hulman Institute of Technology
        time: 2019

experiences:
    title: Experiences
    info:
      - role: Maria Goeppert Mayer Fellow
        time: Oct 2024 - Present
        company: Argonne National Laboratory
        details: |
            - Leading my own research project at the intersection between HPC and AI, excited to share more soon!

      - role: Software Engineer
        time: Jan-Sep 2024
        company: Cornelis Networks
        details: |
            - Optimized the OPX libfabric provider, achieving 5x bandwidth improvements for GPU communication among
            other advancements
            - Led the development of the reference libfabric provider for the Ultra Ethernet Consortium
            - Created developer productivity tooling, including an OPX performance profiler and a runtime parameter
            autotuner

      - role: AI Research Intern
        time: Summer 2023
        company: Meta
        details: |
            - Designed and implemented an application-aware communication (NCCL) autotuner for large-scale AI workloads
            - Developed an AI application emulation tool that mimics production models by overlapping communication and
            genericized compute kernels

      - role: Research Aide/Visiting Student
        time: 2020 - Present
        company: Argonne National Laboratory
        details: |
            - Founded the MPI collective algorithm/machine learning project, initially under the supervision of Dr. Min Si and Dr. Pavan Balaji, now Dr. Yanfei Guo and Dr. Rajeev Thakur
            - Earned perpetual external funding from ANL for the remainder of my Ph.D

      - role: Engineering Leadership Program Intern
        time: Summer 2018
        company: National Instruments
        details: |
            - Engaged with technical leaders through field presentations to multiple companies in the Seattle area
            - Assisted customers to design and troubleshoot data-acquisition applications using NI platforms

      - role: Trailblazer Intern
        time: Summer 2017
        company: Flexware Innovation
        details: |
            - Designed an innovative RFID tracking solution to repair a malfunctioning inventory locating system
            - Produced a full-stack BI database solution analyzing internal employee and revenue data

      - role: Director of Tool Services
        time: Summer 2016
        company: Power Solutions International
        details: |
            - Organized and managed the companyâ€™s inventory of CNC machining tools, valued at more than $500,000
            - Trained company technicians on new processes and managed tool services employees

projects:
    title: Research Projects
    intro: >
          Here is a high-level description of my active and former research projects.
    info:
      - role: ML Autotuning for Generalized MPI Collective Algorithms
        time: Ongoing
        details: |
            - Creating new generalized MPI collective algorithms and a machine-learning autotuner that automatically selects and optimizes the best algorithm
            - Invented multiple optimizations to make ML-based MPI autotuning feasible on large-scale systems
     
      - role: High-Level Parallel Languages for HPC
        time: Ongoing
        details: |
            - Developing a new hardware/software co-design for the Standard ML language targeted at HPC systems and applications, including AI
            - Created a new version of the NAS benchmark suite using MPL (a parallel compiler for Standard ML) to enable direct comparison between HLPLs and lower-level languages for HPC

      - role: Cache Coherence for High-Level Parallel Languages
        time: 2019-2022
        details: |
            - Identified a low-level memory property called WARD that can be introduced by construction in high-level parallel programs
            - Implemented a custom cache coherence protocol in the Sniper architectural simulator and found an average speedup of 1.46x across the PBBS benchmark suite.

      - role: Compiler and Runtime Memory Observation Tool (CARMOT)
        time: 2020-2022
        details: |
            - Implemented source code-level automatic parallelization tool  using compiler and runtime techniques
            - Built a pintool using the Intel pin interface to report memory locations allocated and freed within statically compiled libraries

publications:
    title: Publications
    papers:
      - title: "Generalized Collective Algorithms for the Exascale Era"
        link: "#"
        authors: <strong>Michael Wilkins</strong>, Hanming Wang, Peizhi Liu, Bangyen Pham, Yanfei Guo, Rajeev Thakur, Nikos Hardavellas, and Peter Dinda
        conference: CLUSTER'23

      - title: "Evaluating Functional Memory-Managed Parallel Languages for HPC using the NAS Parallel Benchmarks"
        link: "#"
        authors: <strong>Michael Wilkins</strong>, Garrett Weil, Luke Arnold, Nikos Hardavellas, Peter Dinda      
        conference: HIPS'23 Workshop

      - title: "WARDen: Specializing Cache Coherence for High-Level Parallel Languages"
        link: "#"
        authors: <strong>Michael Wilkins</strong>, Sam Westrick, Vijay Kandiah, Alex Bernat, Brian Suchy, Enrico Armenio Deiana, Simone Campanoni, Umut Acar, Peter Dinda, Nikos Hardavellas
        conference: CGO'23

      - title: "CARMOT: Compiler and Runtime Memory Observation Tool"
        link: "#"
        authors: Enrico Deiana, Brian Suchy, <strong>Michael Wilkins</strong>, Brian Homerding, John McMichen, Nikos Hardavellas, Peter Dinda, Simone Campanoni
        conference: CGO'23
     
      - title: "ACCLAiM: Advancing the Practicality of MPI Collective Communication Autotuning Using Machine Learning"
        link: "#"
        authors: <strong>Michael Wilkins</strong>, Yanfei Guo, Rajeev Thakur, Peter Dinda, Nikos Hardavellas      
        conference: CLUSTER'22

      - title: "A FACT-Based Approach: Making Machine Learning Collective Autotuning Feasible on Exascale Systems"
        link: "#"
        authors: <strong>Michael Wilkins</strong>, Yanfei Guo, Rajeev Thakur, Nikos Hardavellas, Peter Dinda, Min Si      
        conference: ExaMPI'21 Workshop

 

skills:
    title: Skills

    toolset:
      - name: Software/Scripting Languages
      - list: C, C++, Python, Standard/Parallel ML, C#, LabVIEW, Java, SQL, Bash
      - name: Parallel Programming/Communication
      - list: MPI, Libfabric, NCCL, CUDA, Parallel ML, PyTorch
      - name: Simulators/Tools
      - list: ZSim, gem5, Xilinx Vivado, Xilinx ISE, Quartus II
      - name: Hardware Description Languages
      - list: Chisel, VHDL, Verilog, SPICE

footer: >
    Credit to <a href="http://themes.3rdwavemedia.com" target="_blank" rel="nofollow">Xiaoying Riley</a> for the base webpage template
